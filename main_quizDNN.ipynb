{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_quizDNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNxAb2A7ic6e2LKNCjYLcPN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shashank-Holla/CNN_for_CIFAR10/blob/master/main_quizDNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPoCGoxrIjcI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "684ac768-540b-4ba6-fbcb-6ee4085053d9"
      },
      "source": [
        "from datetime import datetime\n",
        "print(\"Current Date/Time: \", datetime.now())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current Date/Time:  2020-03-17 21:43:30.137707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuqnbNWjJO3u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07fe4491-6e0e-42f9-e99b-80a35b9331b3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "512Htx2xJZYk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b34f66d-e504-4326-d7c7-677ed5175537"
      },
      "source": [
        "cd '/gdrive/My Drive/Colab Notebooks/SchoolOfAI/Session7_CIFAR/cnn_for_cifar10/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/Colab Notebooks/SchoolOfAI/Session7_CIFAR/cnn_for_cifar10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUOXctdnJcVk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "310c7743-bbb2-4431-d431-8b75bdd181fa"
      },
      "source": [
        "ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/                                  metrics.py\n",
            "Execute.ipynb                          \u001b[01;34mmodels\u001b[0m/\n",
            "\u001b[01;34mgradcam\u001b[0m/                               \u001b[01;34m__pycache__\u001b[0m/\n",
            "GraphsForLearning.ipynb                test.py\n",
            "ImageAugmentation_Albumentation.ipynb  train.py\n",
            "mainfile.py                            transform_albumentation.py\n",
            "main.ipynb                             Transform_Filecall.ipynb\n",
            "main_quizDNN.ipynb                     transform.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OwYG1haJfZM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "2aecbd33-cb42-414b-86fd-fb29206a8ea7"
      },
      "source": [
        "#import all necessary .py files\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "!pip install -U git+https://github.com/albu/albumentations --no-cache-dir\n",
        "\n",
        "from train import train\n",
        "from test import test\n",
        "from metrics import train_test_metrics_graph\n",
        "\n",
        "#Torchvision transforms\n",
        "#from transform import transform\n",
        "#Albumentations transform\n",
        "from transform_albumentation import transform\n",
        "from models import *\n",
        "from gradcam import *"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/albu/albumentations\n",
            "  Cloning https://github.com/albu/albumentations to /tmp/pip-req-build-8gldbnmt\n",
            "  Running command git clone -q https://github.com/albu/albumentations /tmp/pip-req-build-8gldbnmt\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (1.18.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: imgaug<0.2.7,>=0.2.5 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (0.2.6)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: opencv-python>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (4.1.2.30)\n",
            "Requirement already satisfied, skipping upgrade: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (0.16.2)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.4)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (3.2.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.4.6)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (45.2.0)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.5-cp36-none-any.whl size=64514 sha256=bc34e72a4fc213f583998498bf9056edf2a223fe7d5c8a5200d98963974d4386\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xfsd_hw0/wheels/45/8b/e4/2837bbcf517d00732b8e394f8646f22b8723ac00993230188b\n",
            "Successfully built albumentations\n",
            "Installing collected packages: albumentations\n",
            "  Found existing installation: albumentations 0.4.5\n",
            "    Uninstalling albumentations-0.4.5:\n",
            "      Successfully uninstalled albumentations-0.4.5\n",
            "Successfully installed albumentations-0.4.5\n",
            "Albumentations version: 0.4.5\n",
            "Resnet18 model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gbW7_rtaiB0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "84d48288-b2eb-4e6e-838b-cdeed7af43e2"
      },
      "source": [
        "#Check the number of parameters\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "#My model\n",
        "#net = Net().to(device)\n",
        "\n",
        "#Resnet18 model\n",
        "#net = ResNet18().to(device)\n",
        "\n",
        "#QuizDNN model\n",
        "net = QuizDNN().to(device)\n",
        "\n",
        "summary(net, input_size=(3, 32, 32))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "              ReLU-2           [-1, 64, 32, 32]               0\n",
            "       BatchNorm2d-3           [-1, 64, 32, 32]             128\n",
            "            Conv2d-4            [-1, 3, 32, 32]             192\n",
            "              ReLU-5            [-1, 3, 32, 32]               0\n",
            "       BatchNorm2d-6            [-1, 3, 32, 32]               6\n",
            "            Conv2d-7           [-1, 64, 32, 32]           1,728\n",
            "              ReLU-8           [-1, 64, 32, 32]               0\n",
            "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
            "           Conv2d-10            [-1, 3, 32, 32]             192\n",
            "             ReLU-11            [-1, 3, 32, 32]               0\n",
            "      BatchNorm2d-12            [-1, 3, 32, 32]               6\n",
            "        MaxPool2d-13            [-1, 3, 16, 16]               0\n",
            "           Conv2d-14           [-1, 64, 16, 16]           1,728\n",
            "             ReLU-15           [-1, 64, 16, 16]               0\n",
            "      BatchNorm2d-16           [-1, 64, 16, 16]             128\n",
            "           Conv2d-17            [-1, 3, 16, 16]             192\n",
            "             ReLU-18            [-1, 3, 16, 16]               0\n",
            "      BatchNorm2d-19            [-1, 3, 16, 16]               6\n",
            "           Conv2d-20           [-1, 64, 16, 16]           1,728\n",
            "             ReLU-21           [-1, 64, 16, 16]               0\n",
            "      BatchNorm2d-22           [-1, 64, 16, 16]             128\n",
            "           Conv2d-23            [-1, 3, 16, 16]             192\n",
            "             ReLU-24            [-1, 3, 16, 16]               0\n",
            "      BatchNorm2d-25            [-1, 3, 16, 16]               6\n",
            "           Conv2d-26           [-1, 64, 16, 16]           1,728\n",
            "             ReLU-27           [-1, 64, 16, 16]               0\n",
            "      BatchNorm2d-28           [-1, 64, 16, 16]             128\n",
            "           Conv2d-29            [-1, 3, 16, 16]             192\n",
            "             ReLU-30            [-1, 3, 16, 16]               0\n",
            "      BatchNorm2d-31            [-1, 3, 16, 16]               6\n",
            "        MaxPool2d-32              [-1, 3, 8, 8]               0\n",
            "           Conv2d-33             [-1, 64, 8, 8]           1,728\n",
            "             ReLU-34             [-1, 64, 8, 8]               0\n",
            "      BatchNorm2d-35             [-1, 64, 8, 8]             128\n",
            "           Conv2d-36              [-1, 3, 8, 8]             192\n",
            "             ReLU-37              [-1, 3, 8, 8]               0\n",
            "      BatchNorm2d-38              [-1, 3, 8, 8]               6\n",
            "           Conv2d-39             [-1, 64, 8, 8]           1,728\n",
            "             ReLU-40             [-1, 64, 8, 8]               0\n",
            "      BatchNorm2d-41             [-1, 64, 8, 8]             128\n",
            "           Conv2d-42              [-1, 3, 8, 8]             192\n",
            "             ReLU-43              [-1, 3, 8, 8]               0\n",
            "      BatchNorm2d-44              [-1, 3, 8, 8]               6\n",
            "           Conv2d-45             [-1, 64, 8, 8]           1,728\n",
            "             ReLU-46             [-1, 64, 8, 8]               0\n",
            "      BatchNorm2d-47             [-1, 64, 8, 8]             128\n",
            "        AvgPool2d-48             [-1, 64, 1, 1]               0\n",
            "           Conv2d-49             [-1, 10, 1, 1]             640\n",
            "================================================================\n",
            "Total params: 16,874\n",
            "Trainable params: 16,874\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 4.62\n",
            "Params size (MB): 0.06\n",
            "Estimated Total Size (MB): 4.69\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bruhncDSalAQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d3a41bdd-4173-498b-edee-7cfa8ff8529b"
      },
      "source": [
        "EPOCHS =40\n",
        "train_accuracy = []\n",
        "test_accuracy = []\n",
        "train_loss = []\n",
        "test_loss = []\n",
        "from torch.optim.lr_scheduler import StepLR \n",
        "\n",
        "#import CIFAR10 data. Perform Normalize, Batching through transforms.\n",
        "trainloader, testloader, classes = transform()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Optimum LR for custom_model = 0.015\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.007, momentum=0.9, weight_decay=0.001)\n",
        "# scheduler = StepLR(optimizer, step_size=3, gamma=0.001)\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  print(\"epoch:\", epoch)\n",
        "  train_accuracy_delta, train_loss_delta = train(net, device, trainloader, optimizer, criterion, epoch)\n",
        "  test_accuracy_delta, test_loss_delta = test(net, device, testloader, criterion)\n",
        "  # scheduler.step()\n",
        "  train_accuracy.append(train_accuracy_delta)\n",
        "  train_loss.append(train_loss_delta)\n",
        "  test_accuracy.append(test_accuracy_delta)\n",
        "  test_loss.append(test_loss_delta)\n",
        "  \n",
        "print(\"Train Accuracy-\",train_accuracy)\n",
        "print(\"Test Accuracy-\",test_accuracy)\n",
        "\n",
        "print(\"Train loss-\",train_loss)\n",
        "print(\"Test loss-\",test_loss)\n",
        "train_test_metrics_graph(train_accuracy, train_loss, test_accuracy, test_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set\n",
            "Files already downloaded and verified\n",
            "Test set\n",
            "Files already downloaded and verified\n",
            "epoch: 0\n",
            "[1,   300] loss: 0.310\n",
            "Epoch Train loss: 2.0394561963203626         Epoch Train Accuracy: 22.25\n",
            "Epoch Test loss: 1.7648407326468938         Epoch Test Accuracy: 31.42\n",
            "epoch: 1\n",
            "[2,   300] loss: 0.283\n",
            "Epoch Train loss: 1.889071001456334         Epoch Train Accuracy: 28.524\n",
            "Epoch Test loss: 1.6797449060633212         Epoch Test Accuracy: 36.91\n",
            "epoch: 2\n",
            "[3,   300] loss: 0.278\n",
            "Epoch Train loss: 1.8538346302814972         Epoch Train Accuracy: 30.828\n",
            "Epoch Test loss: 1.6499934875512425         Epoch Test Accuracy: 38.6\n",
            "epoch: 3\n",
            "[4,   300] loss: 0.272\n",
            "Epoch Train loss: 1.8199743221967648         Epoch Train Accuracy: 32.592\n",
            "Epoch Test loss: 1.6105713331246678         Epoch Test Accuracy: 40.41\n",
            "epoch: 4\n",
            "[5,   300] loss: 0.267\n",
            "Epoch Train loss: 1.79038394567294         Epoch Train Accuracy: 33.646\n",
            "Epoch Test loss: 1.5873077413703822         Epoch Test Accuracy: 40.6\n",
            "epoch: 5\n",
            "[6,   300] loss: 0.265\n",
            "Epoch Train loss: 1.769045908940144         Epoch Train Accuracy: 34.678\n",
            "Epoch Test loss: 1.554380575312844         Epoch Test Accuracy: 42.95\n",
            "epoch: 6\n",
            "[7,   300] loss: 0.262\n",
            "Epoch Train loss: 1.749126154031509         Epoch Train Accuracy: 35.714\n",
            "Epoch Test loss: 1.5280755501759202         Epoch Test Accuracy: 44.25\n",
            "epoch: 7\n",
            "[8,   300] loss: 0.259\n",
            "Epoch Train loss: 1.729134340163989         Epoch Train Accuracy: 36.446\n",
            "Epoch Test loss: 1.514286566384231         Epoch Test Accuracy: 44.64\n",
            "epoch: 8\n",
            "[9,   300] loss: 0.257\n",
            "Epoch Train loss: 1.7196609393144264         Epoch Train Accuracy: 36.752\n",
            "Epoch Test loss: 1.513444856752323         Epoch Test Accuracy: 44.48\n",
            "epoch: 9\n",
            "[10,   300] loss: 0.255\n",
            "Epoch Train loss: 1.7077390634096585         Epoch Train Accuracy: 37.534\n",
            "Epoch Test loss: 1.482070942468281         Epoch Test Accuracy: 46.16\n",
            "epoch: 10\n",
            "[11,   300] loss: 0.255\n",
            "Epoch Train loss: 1.7003772570536686         Epoch Train Accuracy: 37.806\n",
            "Epoch Test loss: 1.4878264771232121         Epoch Test Accuracy: 44.74\n",
            "epoch: 11\n",
            "[12,   300] loss: 0.253\n",
            "Epoch Train loss: 1.690709691781264         Epoch Train Accuracy: 38.172\n",
            "Epoch Test loss: 1.460163869435274         Epoch Test Accuracy: 46.91\n",
            "epoch: 12\n",
            "[13,   300] loss: 0.251\n",
            "Epoch Train loss: 1.6785485234016027         Epoch Train Accuracy: 38.91\n",
            "Epoch Test loss: 1.4675271495988098         Epoch Test Accuracy: 46.56\n",
            "epoch: 13\n",
            "[14,   300] loss: 0.251\n",
            "Epoch Train loss: 1.679455164151314         Epoch Train Accuracy: 38.654\n",
            "Epoch Test loss: 1.4575802540477318         Epoch Test Accuracy: 46.79\n",
            "epoch: 14\n",
            "[15,   300] loss: 0.250\n",
            "Epoch Train loss: 1.672921328055553         Epoch Train Accuracy: 38.706\n",
            "Epoch Test loss: 1.4585229671454127         Epoch Test Accuracy: 47.08\n",
            "epoch: 15\n",
            "[16,   300] loss: 0.248\n",
            "Epoch Train loss: 1.6565778457201443         Epoch Train Accuracy: 39.288\n",
            "Epoch Test loss: 1.4746628622465496         Epoch Test Accuracy: 46.33\n",
            "epoch: 16\n",
            "[17,   300] loss: 0.249\n",
            "Epoch Train loss: 1.6612641410949902         Epoch Train Accuracy: 39.34\n",
            "Epoch Test loss: 1.4262787148922305         Epoch Test Accuracy: 47.47\n",
            "epoch: 17\n",
            "[18,   300] loss: 0.247\n",
            "Epoch Train loss: 1.6558298025375757         Epoch Train Accuracy: 39.0\n",
            "Epoch Test loss: 1.4684520552429972         Epoch Test Accuracy: 46.4\n",
            "epoch: 18\n",
            "[19,   300] loss: 0.247\n",
            "Epoch Train loss: 1.6472882848519546         Epoch Train Accuracy: 39.926\n",
            "Epoch Test loss: 1.4481691484209858         Epoch Test Accuracy: 47.1\n",
            "epoch: 19\n",
            "[20,   300] loss: 0.246\n",
            "Epoch Train loss: 1.645492708683014         Epoch Train Accuracy: 39.826\n",
            "Epoch Test loss: 1.4181788722171058         Epoch Test Accuracy: 48.18\n",
            "epoch: 20\n",
            "[21,   300] loss: 0.246\n",
            "Epoch Train loss: 1.6433977429683393         Epoch Train Accuracy: 40.296\n",
            "Epoch Test loss: 1.4315077700192416         Epoch Test Accuracy: 48.05\n",
            "epoch: 21\n",
            "[22,   300] loss: 0.244\n",
            "Epoch Train loss: 1.633711207829989         Epoch Train Accuracy: 40.632\n",
            "Epoch Test loss: 1.4430231112468093         Epoch Test Accuracy: 47.15\n",
            "epoch: 22\n",
            "[23,   300] loss: 0.246\n",
            "Epoch Train loss: 1.6380052288373312         Epoch Train Accuracy: 40.268\n",
            "Epoch Test loss: 1.4281689668003517         Epoch Test Accuracy: 47.77\n",
            "epoch: 23\n",
            "[24,   300] loss: 0.245\n",
            "Epoch Train loss: 1.6351784192598784         Epoch Train Accuracy: 40.422\n",
            "Epoch Test loss: 1.4246567050112953         Epoch Test Accuracy: 48.72\n",
            "epoch: 24\n",
            "[25,   300] loss: 0.243\n",
            "Epoch Train loss: 1.6293188703365815         Epoch Train Accuracy: 40.808\n",
            "Epoch Test loss: 1.421722166145904         Epoch Test Accuracy: 47.81\n",
            "epoch: 25\n",
            "[26,   300] loss: 0.244\n",
            "Epoch Train loss: 1.6266555067820427         Epoch Train Accuracy: 41.022\n",
            "Epoch Test loss: 1.4087452858309202         Epoch Test Accuracy: 49.57\n",
            "epoch: 26\n",
            "[27,   300] loss: 0.242\n",
            "Epoch Train loss: 1.6202723888250499         Epoch Train Accuracy: 41.136\n",
            "Epoch Test loss: 1.4137021816229518         Epoch Test Accuracy: 48.92\n",
            "epoch: 27\n",
            "[28,   300] loss: 0.243\n",
            "Epoch Train loss: 1.6242553096551162         Epoch Train Accuracy: 41.256\n",
            "Epoch Test loss: 1.392134666442871         Epoch Test Accuracy: 50.36\n",
            "epoch: 28\n",
            "[29,   300] loss: 0.242\n",
            "Epoch Train loss: 1.6142964338644956         Epoch Train Accuracy: 41.392\n",
            "Epoch Test loss: 1.40348269215113         Epoch Test Accuracy: 49.09\n",
            "epoch: 29\n",
            "[30,   300] loss: 0.241\n",
            "Epoch Train loss: 1.6092232487140559         Epoch Train Accuracy: 41.698\n",
            "Epoch Test loss: 1.4108126676535304         Epoch Test Accuracy: 48.55\n",
            "epoch: 30\n",
            "[31,   300] loss: 0.241\n",
            "Epoch Train loss: 1.6128372219892648         Epoch Train Accuracy: 41.46\n",
            "Epoch Test loss: 1.3945845803128014         Epoch Test Accuracy: 49.62\n",
            "epoch: 31\n",
            "[32,   300] loss: 0.241\n",
            "Epoch Train loss: 1.610471396568494         Epoch Train Accuracy: 41.638\n",
            "Epoch Test loss: 1.419531844839265         Epoch Test Accuracy: 48.22\n",
            "epoch: 32\n",
            "[33,   300] loss: 0.241\n",
            "Epoch Train loss: 1.609370083380968         Epoch Train Accuracy: 41.59\n",
            "Epoch Test loss: 1.3935426518886904         Epoch Test Accuracy: 49.01\n",
            "epoch: 33\n",
            "[34,   300] loss: 0.239\n",
            "Epoch Train loss: 1.6006484257869231         Epoch Train Accuracy: 42.22\n",
            "Epoch Test loss: 1.4270335843291464         Epoch Test Accuracy: 48.32\n",
            "epoch: 34\n",
            "[35,   300] loss: 0.241\n",
            "Epoch Train loss: 1.6053239865180773         Epoch Train Accuracy: 41.686\n",
            "Epoch Test loss: 1.3941242000724696         Epoch Test Accuracy: 49.5\n",
            "epoch: 35\n",
            "[36,   300] loss: 0.239\n",
            "Epoch Train loss: 1.5983929762473472         Epoch Train Accuracy: 41.92\n",
            "Epoch Test loss: 1.3857165665566167         Epoch Test Accuracy: 50.02\n",
            "epoch: 36\n",
            "[37,   300] loss: 0.239\n",
            "Epoch Train loss: 1.596326198333349         Epoch Train Accuracy: 42.166\n",
            "Epoch Test loss: 1.3804277604139303         Epoch Test Accuracy: 50.84\n",
            "epoch: 37\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}